{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel, pairwise_distances\n",
    "\n",
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### functions\n",
    "\n",
    "output_file_template = \"\"\"\n",
    "<h3>书签目录</h3>\n",
    "{catelog}\n",
    "{bookmark_bar}\n",
    "\n",
    "{other}\n",
    "\"\"\"\n",
    "\n",
    "output_file_template = \"\"\"\n",
    "<h3>我來測試啦~~~~</h3>\n",
    "{other}\n",
    "\"\"\"\n",
    "\n",
    "# 过滤 name\n",
    "filter_name_list = {'My work', '书签栏', 'websites'}\n",
    "\n",
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&#39;\",\n",
    "    \">\": \"&gt;\",\n",
    "    \"<\": \"&lt;\",\n",
    "}\n",
    "\n",
    "\n",
    "def html_escape(text):\n",
    "    return ''.join(html_escape_table.get(c, c) for c in text)\n",
    "\n",
    "def html_for_node(node):    # node 是個 dictionary\n",
    "    # 判断 url 和 children 即判断是否包含在文件夹中\n",
    "    if 'url' in node:\n",
    "        return html_for_url_node(node)\n",
    "    elif 'children' in node:\n",
    "        return html_for_parent_node(node) #處理資料夾\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def html_for_url_node(node):\n",
    "    if not re.match(\"javascript:\", node['url']):\n",
    "        return f'- [{node['name']}]({node['url']})\\n'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def html_for_parent_node(node): #有<h4,列資料夾名>\n",
    "    return f'{filter_catelog_name(node)}\\n\\n{''.join([filter_name(n) for n in node['children']])}\\n'\n",
    "\n",
    "# 过滤文件夹\n",
    "def filter_name(n):\n",
    "    if n['name'] in filter_name_list:\n",
    "        return ''\n",
    "    else:\n",
    "        return html_for_node(n)\n",
    "\n",
    "# 过滤目录名\n",
    "def filter_catelog_name(n):\n",
    "    if n['name'] in filter_name_list:\n",
    "        return ''\n",
    "    else:\n",
    "        catelog.append('- [{0}](#{0})\\n'.format(n['name']))\n",
    "        return '<h4 id={0}>{0}</h4>'.format(n['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Bookmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data 一次就好\n",
    "\n",
    "catelog = list() # 目录\n",
    "\n",
    "print(os.environ[\"LOCALAPPDATA\"])\n",
    "input_filename = os.environ[\"LOCALAPPDATA\"] + r\"\\Google\\Chrome\\User Data\\Default\\Bookmarks\"\n",
    "\n",
    "with open(input_filename, 'r', encoding='utf-8') as f:\n",
    "    contents = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "### contents 結構：\n",
    "\n",
    "```python\n",
    "{  \n",
    "    'checksum': <str>,    # 一個檢查用的資訊  \n",
    "    'roots': {  \n",
    "        'bookmark_bar': {  \n",
    "            'children': [<nested with dicts with structure same as this dict>],  \n",
    "            'date_added': <str with numbers>,  \n",
    "            'date_modified': <str with numbers>,  \n",
    "            'guid': <str>,    # example: '00000000-0000-4000-a000-000000000002'  \n",
    "            'id': <str with numbers>,  \n",
    "            'name': <str>,  \n",
    "            'type': <str>    # 有 folder, url  \n",
    "        },  \n",
    "        'other': {<same as bookmark_bar>},  \n",
    "        'synced' {<same as bookmark_bar>}:  \n",
    "    },  \n",
    "    sync_metadata: <str>,    # 一大串不知道幹嘛的亂碼  \n",
    "    version: <int>  \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_info(root, parent_name):\n",
    "    children = root.pop('children', None)\n",
    "    root['parent'] = parent_name\n",
    "    info_list = [root]\n",
    "    \n",
    "    if children:\n",
    "        for child in children:\n",
    "            info_list.extend(get_nodes_info(child, root['name']))\n",
    "    \n",
    "    return info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmark_bar_info = get_nodes_info(contents['roots']['bookmark_bar'], 'bookmark_bar')\n",
    "other_info = get_nodes_info(contents['roots']['other'], 'other')\n",
    "synced_info = get_nodes_info(contents['roots']['synced'], 'synced')\n",
    "\n",
    "info = bookmark_bar_info + other_info + synced_info\n",
    "\n",
    "df = pd.DataFrame(info)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.analyse.set_stop_words('meaningless_words.txt')\n",
    "\n",
    "df['keyword'] = df['name'].progress_apply(jieba.analyse.tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "key: 列出不重複的tags，value: 每個tag分別有哪些書籤\n",
    "record: {tag: [associated_url_index, ...]}\n",
    "\"\"\"\n",
    "\n",
    "keywords = [keyword for keywords in df['keyword'] for keyword in keywords]\n",
    "keywords = list(set(keywords))\n",
    "\n",
    "tag2urls = {k:[] for k in keywords}\n",
    "\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    for item in row['keyword']:\n",
    "        tag2urls[item].append(row['id'])\n",
    "\n",
    "tag_df = pd.DataFrame(tag2urls.items(), columns=['tag', 'indices'])\n",
    "tag_df['len'] = tag_df['indices'].apply(len)\n",
    "\n",
    "tag_df = tag_df.sort_values('len', ascending=False)\n",
    "\n",
    "display(tag_df.head(10), tag_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword_indices\n",
    "index2tag = dict(tag_df['tag'])\n",
    "tag2index = {index2tag[k]: k for k in index2tag}\n",
    "\n",
    "df['keyword_indices'] = df['keyword'].apply(lambda keywords: [tag2index[k] for k in keywords])\n",
    "\n",
    "\n",
    "# onehot\n",
    "def keyword_indices_to_vector(indices):\n",
    "    vec = np.zeros([len(keywords)])\n",
    "    for index in indices:\n",
    "        vec[index] += 1\n",
    "    return vec\n",
    "\n",
    "onehot = df['keyword_indices'].apply(keyword_indices_to_vector)\n",
    "onehot = np.stack(onehot.values)\n",
    "df['onehot'] = onehot.tolist()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_name(find_similar_function):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        result = find_similar_function(*args, **kwargs)\n",
    "        return result.apply(lambda x: [df.loc[idx, 'name'] for idx in x])\n",
    "    return wrapped\n",
    "\n",
    "@return_name\n",
    "def linear_kernel_highpass(vectors, threshold=1):\n",
    "    \"\"\"\n",
    "    如果 vectors 是 onehot，threshold = 0，那相當於找出擁有同關鍵字的 url 們。\n",
    "    \"\"\"\n",
    "    kernel = linear_kernel(onehot)\n",
    "    s = pd.Series(kernel.tolist())\n",
    "    similar_series = s.apply(lambda x: [idx for idx in np.where(np.array(x) >= threshold)[0]])\n",
    "    return similar_series\n",
    "\n",
    "@return_name\n",
    "def l2norm_lowpass(vectors, threshold=1):\n",
    "    kernel = pairwise_distances(onehot)\n",
    "    s = pd.Series(kernel.tolist())\n",
    "    similar_series = s.apply(lambda x: [idx for idx in np.where(np.array(x) <= threshold)[0]])\n",
    "    return similar_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df['linear_kernel'] = linear_kernel_highpass(onehot)\n",
    "%time df['l2_norm'] = l2norm_lowpass(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', 500):\n",
    "    display(df[['name', 'parent', 'linear_kernel', 'l2_norm']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. [x] 加入'tag' by 斷詞\n",
    "2. [x] 加入母資料夾\n",
    "3. [ ] 類似的東東們，i.e. recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adam\n",
    "可以用 folder 當作 y，去 train 關鍵字的距離\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Adam\n",
    "也許可以用 character-wise 的 embedding 來算 onehot 距離之類的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 現在要做出 recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### main do things and output to md\n",
    "\n",
    "bookmark_bar = html_for_node(contents['roots']['bookmark_bar'])\n",
    "other = html_for_node(contents['roots']['other'])\n",
    "catelog_str = ''.join(a for a in catelog)\n",
    "\n",
    "output_file_name = \"output_markdown.md\"\n",
    "with open(output_file_name, 'w', encoding='utf-8') as f:\n",
    "#     f.write(output_file_template.format(catelog=catelog_str, bookmark_bar=bookmark_bar, other=other))    # origin\n",
    "    f.write(output_file_template.format(other=other))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_thumb_img(url):\n",
    "#     load_html\n",
    "#     load_all_img\n",
    "#     find_max_img\n",
    "\n",
    "# route = download_thumb_img(googlebookmarkinfo['url'][idx])    # ex: 'C:/example.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬一個網址中的所有圖片"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = 'https://github.com/Alex-CHUN-YU/Word2vec'\n",
    "url = 'https://www.youtube.com/watch?v=nrm3UaMAWOg'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Below is tumblr climber 用來改的\n",
    "\n",
    "tum_img_filter  = re.compile('http[s]?://\\w+.media.tumblr.com/\\w+/\\w+\\.(?:jpg|png|gif)')\n",
    "alltype_img_filter = re.compile('http[s]?://\\S+\\.(?:jpg|png|gif)')\n",
    "\n",
    "def true_name(x): #重新命名，處理資料夾違法命名\n",
    "\tfor i in [':','\\n','?','/','|','*','>','<','=']:\n",
    "\t\tx = x.replace(i,'')\n",
    "\treturn x\n",
    "\n",
    "def download_all_images(url):\n",
    "    res = requests.get(url) #這是一個class\t#print(res.text) #裡面的text屬性就是html原始碼\n",
    "    html = BeautifulSoup(res.text,'html.parser') #也是建立class\t# print(html.title) #這樣印會含有<title>\t# print(html.title.text) #這個就是真正的title\n",
    "    imageset = alltype_img_filter.findall(res.text) #符合filter規則的弄成一個list\n",
    "    max_value = 0\n",
    "    for img_route in set(imageset): #要找到最大的下載\n",
    "        print(img_route)\n",
    "#         now_pic = cv2.imread(img_route)\n",
    "#         if 大小(now_pic)>max_value:\n",
    "#             max_img_route = img_route\n",
    "#     try:\n",
    "#         urlretrieve(max_img_route,os.path.join('Thumb_pic_Dataset',(guid+'.jpg')))\n",
    "#     except: #回傳爬不到的網址到txt\n",
    "#         print(\"GGGGGGGGGGGGGGGGGGG有問題:\"+url)\n",
    "#         faillist.append(url)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "download_all_images(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
